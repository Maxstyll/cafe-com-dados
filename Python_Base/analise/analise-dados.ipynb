{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd03986840a6b217fa63296dd3c98d2e182c477b99e0fa07e11ae4beefadba0e2c6",
   "display_name": "Python 3.8.5 64-bit ('cfd-3.8.5': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "3986840a6b217fa63296dd3c98d2e182c477b99e0fa07e11ae4beefadba0e2c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Distribuicões de variáveis dentro das classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as Bibliotecas\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = datasets.load_iris()\n",
    "name_columns = df_iris.feature_names\n",
    "des_target = df_iris.target_names\n",
    "\n",
    "df = pd.DataFrame(data=df_iris.data, columns=name_columns)\n",
    "df['target'] = df_iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collections.Counter(df_iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in name_columns:\n",
    "    print(f\"Feature analizada: {feature}\")\n",
    "    sn.catplot(x=\"target\", y=feature, kind=\"box\", data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "## Escor Z\n",
    "\n",
    "Às vezes, os dados são padronizados primeiro (por exemplo, para um escore Z com média zero e variância da unidade) de modo que a detecção de outlier possa ser realizada usando valores de corte de escore Z padrão. Isso é uma conveniência e não é obrigatório em geral, e faremos os cálculos na escala original dos dados aqui para tornar as coisas mais claras. Podemos calcular a média e o desvio padrão de uma determinada amostra e, em seguida, calcular o cut-off para identificar outliers como mais de 2 desvios padrão da média."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variavel in name_columns:\n",
    "    df_defaut = []\n",
    "    for value, target in enumerate(des_target):\n",
    "        dados = df[df[\"target\"]==value]\n",
    "        print(f\"Classe: {des_target[value]} - variavel: {variavel}\")\n",
    "\n",
    "        data_mean, data_std = dados[variavel].mean(), dados[variavel].std()\n",
    "        data_min, data_max = dados[variavel].min(), dados[variavel].max()\n",
    "        print(\"Real Min: %.3f Real Max: %.3f\" %  (data_min, data_max))\n",
    "\n",
    "        cut_off = data_std * 2.5\n",
    "        lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "        print(\"Limit Min: %.3f Limit Max: %.3f\" %  (lower, upper))\n",
    "\n",
    "\n",
    "        dataset = dados[dados[variavel] >= lower]\n",
    "        if len(dataset) == 0:\n",
    "            dataset = dados[dados[variavel] <= upper]\n",
    "        else:\n",
    "            dataset = dataset[dataset[variavel] <= upper]\n",
    "\n",
    "\n",
    "        df_defaut.append(dataset)\n",
    "\n",
    "        outliers = pd.concat([dados[dados[variavel] < lower], dados[dados[variavel] > upper]])\n",
    "        print(\"Identfied outliers: %d \\n\" % len(outliers))\n",
    "\n",
    "    df = pd.concat(df_defaut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape : {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collections.Counter(df.target))"
   ]
  },
  {
   "source": [
    "## Lidando com Dados Desbalanceados\n",
    "\n",
    "Após essa introdução e apresentação dos problemas causados pelos Dados Desbalanceados, vamos agora estudar algumas das formas mais comuns que existem para resolver esse empecilho.\n",
    "\n",
    "### Reestruturação dos Dados\n",
    "Uma forma de tirar o viés causado pela diferença de proporção das categorias consiste em manipular a quantidade de dados que são efetivamente utilizados pelo modelo de Machine Learning, tentando igualar o número de observações entre as classes.\n",
    "\n",
    "### Undersampling\n",
    "Esse método consiste em reduzir o número de observações da classe majoritária para diminuir a diferença entre as categorias.\n",
    "\n",
    "* **Random Undersampler:** que consiste na retirada aleatória de dados da classe majoritária (o que acarreta em uma perda grave de informação)\n",
    "\n",
    "* **NearMiss:** Refere-se a uma coleção de métodos de sub-amostragem que selecionam exemplos com base na distância dos exemplos de classes majoritárias aos exemplos de classes minoritárias.\n",
    "\n",
    "ref: https://python-data-science.readthedocs.io/en/latest/classimbalance.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera dataset e labels\n",
    "y = df[\"target\"].to_numpy()\n",
    "X = df\n",
    "X = X.drop(\"target\", axis=1)\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Undersampler\n",
    "rus = RandomUnderSampler(random_state = 32)\n",
    "X_rus_res, y_rus_res = rus.fit_resample(X, y)\n",
    "print(collections.Counter(y_rus_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearMiss\n",
    "nm = NearMiss(version=1)\n",
    "X_nm_res, y_nm_res = nm.fit_resample(X, y)\n",
    "print(collections.Counter(y_nm_res))"
   ]
  },
  {
   "source": [
    "### Oversampling\n",
    "Ao contrário do Undersampling, o Oversampling consiste em criar sinteticamente novas observações da classe minoritária, com o objetivo de igualar a proporção das categorias.\n",
    "\n",
    "* **SMOTE (Synthetic Minority Oversampling Technique):** Um problema com a classificação desequilibrada é que há poucos exemplos da classe da minoria para que um modelo aprenda efetivamente o limite de decisão. Uma melhoria na duplicação de exemplos da classe minoritária é sintetizar novos exemplos da classe minoritária. Este é um tipo de aumento de dados para dados tabulares e pode ser muito eficaz."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overSampling = SMOTE()\n",
    "X, y = overSampling.fit_resample(X, y)\n",
    "print(collections.Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}